{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "OPENAI_API_KEY = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader=TextLoader('analects_raw.txt',encoding='utf-8')\n",
    "data=loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=10)\n",
    "splits=text_splitter.split_documents(data)\n",
    "embedding=OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "vectordb=Chroma.from_documents(\n",
    "    documents=splits,embedding=embedding,collection_name='personal-data'\n",
    ")\n",
    "llm=ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "personal_data=RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type='stuff',retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47181e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "personal_data_tool=Tool(\n",
    "    name='PersonalData',\n",
    "    func=personal_data.run,\n",
    "    description='논어 데이터'\n",
    ")\n",
    "memory_key='history'\n",
    "memory=ConversationBufferMemory(memory_key=memory_key,return_messages=True,input_key=\"input\",output_key=\"output\")\n",
    "\n",
    "system_message=SystemMessage(\n",
    "    content=(\n",
    "        \"\"\"\n",
    "        항상 논어 데이터만을 활용해서 논어랑 가장 관련성 높은 대답을 해줘\n",
    "        너가 말한 내용의 근거를 내가 준 논어 데이터에서 찾아서 그대로 말해줘\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "prompt=OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)]\n",
    ")\n",
    "tools=[personal_data_tool]\n",
    "agent=OpenAIFunctionsAgent(llm=llm,tools=tools,prompt=prompt)\n",
    "agent_executor=AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    return_intermediate_steps=True, #Added\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import  PromptTemplate\n",
    "import pickle\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "with open(\"conf_styles.pickle\", \"rb\") as pr:\n",
    "    examples = pickle.load(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cb7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples, OpenAIEmbeddings(), Chroma, k=2\n",
    ")\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\n",
    "    \"\"\"\n",
    "너는 사용자의 문장을 공자의 말투로 바꿔주는 인공지능이야.\n",
    "사용자의 질문을 공자라면 어떻게 말했을지 생각해서 같은 의미의 문장을 답변해줘.\n",
    "반드시 공자의 말투로 번호식으로 배열보다는 줄글로 답변해줘.\n",
    "공자가 말하듯이 공자의 1인칭으로 말해줘\n",
    "\"\"\",\n",
    "    suffix=\"Input: {input_noun}\\n\",\n",
    "    input_variables=[\"input_noun\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945be7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "chain = LLMChain(llm=chat_model, prompt=similar_prompt, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06318e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_text = '효도란 무엇인가'\n",
    "result = agent_executor({'input':input_text})\n",
    "conf_result = chain(similar_prompt.format(input_noun=result['output']))\n",
    "print(conf_result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain for comparison\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_2 = PromptTemplate(input_variables=[\"in\"],\n",
    "template=\"\"\"\n",
    "효란 무엇인가.\n",
    "input:{in}\n",
    "\"\"\")\n",
    "chat_model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "chain_b = LLMChain(llm=chat_model,prompt=prompt_2, verbose=True)\n",
    "\n",
    "input_text =\"\"\"adskfhasfl\"\"\"\n",
    "conf_result_b = chain_b(input_text)\n",
    "print(conf_result_b[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d05b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation-Agent Trajectory \n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "evaluator = load_evaluator(\"trajectory\")\n",
    "evaluation_result = evaluator.evaluate_agent_trajectory(\n",
    "    prediction=result[\"output\"],\n",
    "    input=result[\"input\"],\n",
    "    agent_trajectory=result[\"intermediate_steps\"],\n",
    ")\n",
    "evaluation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5488a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation-correctness criterion\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "evaluator = load_evaluator(\"labeled_criteria\", criteria=\"correctness\")\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    prediction=conf_result[\"text\"],\n",
    "    reference=\"\",\n",
    "    input=input_text,\n",
    ")\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c77c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation-custom criterion\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "custom_criterion = {\n",
    "    \"historic\": \"Does the output contains ancient wisdom?\"\n",
    "    \n",
    "}\n",
    "evaluator_custom =  load_evaluator(\n",
    "    #\"criteria\",\n",
    "    \"score_string\",\n",
    "    criteria = custom_criterion,\n",
    ")\n",
    "eval_result = evaluator_custom.evaluate_strings(\n",
    "    #prediction=conf_result[\"text\"],\n",
    "    prediction=conf_result_b[\"text\"],\n",
    "    input=input_text,\n",
    ")\n",
    "print(eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
