{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ca528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.tools import Tool\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "#import env\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=TextLoader('analects_raw.txt',encoding='utf-8')\n",
    "data=loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=10)\n",
    "splits=text_splitter.split_documents(data)\n",
    "embedding=OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "vectordb=Chroma.from_documents(\n",
    "    documents=splits,embedding=embedding,collection_name='personal-data'\n",
    ")\n",
    "llm=ChatOpenAI(temperature=0)\n",
    "personal_data=RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type='stuff',retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47181e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data_tool=Tool(\n",
    "    name='PersonalData',\n",
    "    func=personal_data.run,\n",
    "    description='논어 데이터'\n",
    ")\n",
    "memory_key='history'\n",
    "memory=ConversationBufferMemory(memory_key=memory_key,return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee3311",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessage(\n",
    "    content=(\n",
    "        '항상 논어 데이터만을 활용해서 논어랑 가장 관련성 높은 대답을 해줘'\n",
    "        '너가 말한 내용의 근거를 내가 준 논어 데이터에서 찾아서 그대로 말해줘'\n",
    "        #'논어의 어디서 가져왔는지 출처도 내용과 같이 알려줘.'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0097a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[personal_data_tool]\n",
    "agent=OpenAIFunctionsAgent(llm=llm,tools=tools,prompt=prompt)\n",
    "agent_executor=AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8815ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor=AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e758d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result=agent_executor({'input': '공자님 안녕하세요.'},return_only_outputs=True)\n",
    "prompt=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import  PromptTemplate\n",
    "import pickle\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "with open(\"conf_styles.pickle\", \"rb\") as pr:\n",
    "    examples = pickle.load(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cb7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples, OpenAIEmbeddings(), Chroma, k=4\n",
    ")\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"\"\"\n",
    "너는 사용자의 문장을 공자의 말투로 바꿔주는 인공지능이야.\n",
    "사용자의 질문을 공자라면 어떻게 말했을지 생각해서 같은 의미의 문장을 답변해줘.\n",
    "반드시 공자의 말투로 줄글로 답변해주어야 해. \n",
    "\"\"\",\n",
    "    suffix=\"Input: {input_noun}\\n\",\n",
    "    input_variables=[\"input_noun\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945be7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "chain = LLMChain(llm=chat_model, prompt=similar_prompt, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dce47b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_result = chain(similar_prompt.format(input_noun=result['output']))\n",
    "conf_result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06318e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(sys.argv)>1:\n",
    "    prompt=sys.argv[1]\n",
    "    \n",
    "while True:\n",
    "    if not prompt:\n",
    "        prompt = input('\\033[31m\\r\\nPrompt: \\033[0m')\n",
    "    if prompt in ['quit','q','exit']:\n",
    "        sys.exit()\n",
    "    \n",
    "    result=agent_executor({'input':prompt},return_only_outputs=True)\n",
    "    conf_result = chain(similar_prompt.format(input_noun=result['output']))\n",
    "    print(conf_result[\"text\"])\n",
    "    \n",
    "    prompt=None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
